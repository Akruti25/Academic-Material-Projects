{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# if you see error run this block twice"
      ],
      "metadata": {
        "id": "IAwwjuilgah0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slOdId6rzNaH"
      },
      "outputs": [],
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy==1.25\n",
        "\n",
        "## restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ],
      "metadata": {
        "id": "l5PmJBlhzzt6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 0  #TODO: set seed to stuent ID number\n",
        "np.random.seed(SEED) #TODO: random number generator seed set to stuent ID number"
      ],
      "metadata": {
        "id": "Q8mPsnL5zS1H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the input data\n",
        "def preprocess(dataset, epoch):\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
        "        y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(epoch).shuffle(100, seed=SEED).batch(\n",
        "      20).map(batch_format_fn).prefetch(10)\n",
        "\n",
        "# combine data from multiple clients\n",
        "def make_federated_data(client_data, client_ids, epoch):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x), epoch)\n",
        "      for x in client_ids\n",
        "  ]"
      ],
      "metadata": {
        "id": "m03_8F9izTT2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the MNIST data\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
        "print (\"Total number of clients: \",len(emnist_train.client_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQBx7Z70zXYw",
        "outputId": "8560c3fe-7e74-4483-f5e8-cb134bde7ca6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of clients:  3383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the sample data input data structure for ML model\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])\n",
        "preprocessed_example_dataset = preprocess(example_dataset,0)\n",
        "\n",
        "# Neural network model\n",
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "\n",
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "nbM9xB28zck_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 1 #TODO: change number of clients as needed\n",
        "NUM_EPOCHS = 1 #TODO: change the number of training epoch for local training by each client\n",
        "\n",
        "## TODO: you need to iteratively change NUM_CLIENTS for part 'a'\n",
        "## TODO: you need to iteratively change NUM_EPOCHS for part 'b'\n",
        "\n",
        "sample_clients = np.random.choice(emnist_train.client_ids, NUM_CLIENTS)\n",
        "print (\"Client IDs selected: \", sample_clients)\n",
        "\n",
        "# conside data from only the selected clients\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients, NUM_EPOCHS)\n",
        "print(f'Number of client datasets considered: {len(sample_clients)}')\n",
        "\n",
        "# Initialize the iterative training object with the right learning parameter\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "# initialize the parameters of the ML model (you need to initialize this each time you change the client number or epoch numer)\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "# total number of server and client interactions\n",
        "NUM_ROUNDS = 11\n",
        "for round_num in range(1, NUM_ROUNDS):\n",
        "  result, metrics = iterative_process.next(state, federated_train_data)\n",
        "  state = result\n",
        "  print('round {:2d}, training accuracy= {}%'.format(round_num, metrics['client_work']['train']['sparse_categorical_accuracy']*100))\n",
        "\n",
        "# evalute the latest converged model\n",
        "federated_test_data = make_federated_data(emnist_test, sample_clients,1)\n",
        "result, metrics = iterative_process.next(state, federated_test_data)\n",
        "print('Test accuracy= {}%'.format(metrics['client_work']['train']['sparse_categorical_accuracy']*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkcJGifXzhVZ",
        "outputId": "40abe229-249e-45bc-8661-33894b31c64e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client IDs selected:  ['f0459_12']\n",
            "Number of client datasets considered: 1\n",
            "round  1, training accuracy= 12.790697813034058%\n",
            "round  2, training accuracy= 11.627907305955887%\n",
            "round  3, training accuracy= 11.627907305955887%\n",
            "round  4, training accuracy= 12.790697813034058%\n",
            "round  5, training accuracy= 16.27907007932663%\n",
            "round  6, training accuracy= 16.27907007932663%\n",
            "round  7, training accuracy= 16.27907007932663%\n",
            "round  8, training accuracy= 17.44185984134674%\n",
            "round  9, training accuracy= 18.60465109348297%\n",
            "round 10, training accuracy= 18.60465109348297%\n",
            "Test accuracy= 20.000000298023224%\n"
          ]
        }
      ]
    }
  ]
}