{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# if you see error run this block twice"
      ],
      "metadata": {
        "id": "IAwwjuilgah0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "slOdId6rzNaH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "404f774b-d873-4f2c-8503-5871c733c2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.25.2\n",
            "Uninstalling numpy-1.25.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.10\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.25.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-5007b62f.3.23.dev.so\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.25.2\n",
            "Collecting numpy==1.25\n",
            "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "flax 0.7.5 requires jax>=0.4.19, but you have jax 0.4.14 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy==1.25\n",
        "\n",
        "## restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ],
      "metadata": {
        "id": "l5PmJBlhzzt6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 200474710  #TODO: set seed to stuent ID number\n",
        "np.random.seed(SEED) #TODO: random number generator seed set to stuent ID number"
      ],
      "metadata": {
        "id": "Q8mPsnL5zS1H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the input data\n",
        "def preprocess(dataset, epoch):\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
        "        y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(epoch).shuffle(100, seed=SEED).batch(\n",
        "      20).map(batch_format_fn).prefetch(10)\n",
        "\n",
        "# combine data from multiple clients\n",
        "def make_federated_data(client_data, client_ids, epoch):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x), epoch)\n",
        "      for x in client_ids\n",
        "  ]"
      ],
      "metadata": {
        "id": "m03_8F9izTT2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the MNIST data\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
        "print (\"Total number of clients: \",len(emnist_train.client_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQBx7Z70zXYw",
        "outputId": "546afb17-5231-4df7-98f0-b8d126f61847"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading emnist_all.sqlite.lzma: 100%|██████████| 170507172/170507172 [00:24<00:00, 7041006.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of clients:  3383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the sample data input data structure for ML model\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])\n",
        "preprocessed_example_dataset = preprocess(example_dataset,0)\n",
        "\n",
        "# Neural network model\n",
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "\n",
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "nbM9xB28zck_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM_CLIENTS = 1 #TODO: change number of clients as needed\n",
        "#NUM_EPOCHS = 1 #TODO: change the number of training epoch for local training by each client\n",
        "\n",
        "## TODO: you need to iteratively change NUM_CLIENTS for part 'a'\n",
        "#PART A:\n",
        "#part a asks us to fix the number of epochs to 5.\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "#putting the whole block in the loop and iteratign over the num_clients\n",
        "for NUM_CLIENTS in [5, 25, 50]:\n",
        "    sample_clients = np.random.choice(emnist_train.client_ids, NUM_CLIENTS)\n",
        "    print(\"Number of clients selected: \", NUM_CLIENTS)\n",
        "\n",
        "    # consider data from only the selected clients\n",
        "    federated_train_data = make_federated_data(emnist_train, sample_clients, NUM_EPOCHS)\n",
        "    print(f'Number of epochs considered: {NUM_EPOCHS}')\n",
        "\n",
        "    # Initialize the iterative training object with the right learning parameter\n",
        "    iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "    # initialize the parameters of the ML model (you need to initialize this each time you change the client number or epoch numer)\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    # total number of server and client interactions\n",
        "    NUM_ROUNDS = 11\n",
        "    for round_num in range(1, NUM_ROUNDS):\n",
        "      result, metrics = iterative_process.next(state, federated_train_data)\n",
        "      state = result\n",
        "      print('round {:2d}, training accuracy= {}%'.format(round_num, metrics['client_work']['train']['sparse_categorical_accuracy']*100))\n",
        "\n",
        "    # evalute the latest converged model\n",
        "    federated_test_data = make_federated_data(emnist_test, sample_clients,1)\n",
        "    result, metrics = iterative_process.next(state, federated_test_data)\n",
        "    print('Test accuracy= {}%'.format(metrics['client_work']['train']['sparse_categorical_accuracy']*100))"
      ],
      "metadata": {
        "id": "jkcJGifXzhVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ## TODO: you need to iteratively change NUM_EPOCHS for part 'b'\n",
        " #PART B\n",
        " #asks us to fix num of clients to 5\n",
        "NUM_CLIENTS = 5\n",
        "\n",
        "# puttting the whole block in loop and iterating over num_epochs\n",
        "for NUM_EPOCHS in [5, 50, 100]:\n",
        "    sample_clients = np.random.choice(emnist_train.client_ids, NUM_CLIENTS)\n",
        "    print(\"Number of clients selected: \", NUM_CLIENTS)\n",
        "\n",
        "    # consider data from only the selected clients\n",
        "    federated_train_data = make_federated_data(emnist_train, sample_clients, NUM_EPOCHS)\n",
        "    print(f'Number of epochs considered: {NUM_EPOCHS}')\n",
        "\n",
        "    # Initialize the iterative training object with the right learning parameter\n",
        "    iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "    # initialize the parameters of the ML model (you need to initialize this each time you change the client number or epoch numer)\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    # total number of server and client interactions\n",
        "    NUM_ROUNDS = 11\n",
        "    for round_num in range(1, NUM_ROUNDS):\n",
        "      result, metrics = iterative_process.next(state, federated_train_data)\n",
        "      state = result\n",
        "      print('round {:2d}, training accuracy= {}%'.format(round_num, metrics['client_work']['train']['sparse_categorical_accuracy']*100))\n",
        "\n",
        "    # evalute the latest converged model\n",
        "    federated_test_data = make_federated_data(emnist_test, sample_clients,1)\n",
        "    result, metrics = iterative_process.next(state, federated_test_data)\n",
        "    print('Test accuracy= {}%'.format(metrics['client_work']['train']['sparse_categorical_accuracy']*100))"
      ],
      "metadata": {
        "id": "TwPDVETVhyro"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}